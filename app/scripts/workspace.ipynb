{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "84e87b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from alpha_vantage.timeseries import TimeSeries as TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13e47afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1MYLPNITIDL3DGOT\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"ALPHA_VANTAGE_API_KEY\")\n",
    "BASE_URL = \"https://www.alphavantage.co/query\"\n",
    "print(API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08fbc9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKERS = [\"AAPL\", \"MSFT\", \"NVDA\", \"TSLA\", \"AMZN\"]\n",
    "ts= TS(key=API_KEY, output_format='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "054d187b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AAPL data saved to /home/Stock_pipeline/data/raw/2025-06-04/AAPL_daily_2025-06-04.csv.\n",
      " MSFT data saved to /home/Stock_pipeline/data/raw/2025-06-04/MSFT_daily_2025-06-04.csv.\n",
      " NVDA data saved to /home/Stock_pipeline/data/raw/2025-06-04/NVDA_daily_2025-06-04.csv.\n",
      " TSLA data saved to /home/Stock_pipeline/data/raw/2025-06-04/TSLA_daily_2025-06-04.csv.\n",
      " AMZN data saved to /home/Stock_pipeline/data/raw/2025-06-04/AMZN_daily_2025-06-04.csv.\n"
     ]
    }
   ],
   "source": [
    "def fetch_and_save_stock_data(symbol):\n",
    "    try:\n",
    "        data, meta_data = ts.get_daily(symbol=symbol, outputsize='full')\n",
    "        data['ticker'] = symbol\n",
    "        data.index = pd.to_datetime(data.index)\n",
    "        data.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        ingest_filepath = f\"/home/Stock_pipeline/data/raw/{timestamp}/\"\n",
    "        os.makedirs(ingest_filepath, exist_ok=True)\n",
    "        \n",
    "        filename = f\"{ingest_filepath}{symbol}_daily_{timestamp}.csv\"\n",
    "\n",
    "        data.to_csv(filename)\n",
    "        print(f\" {symbol} data saved to {filename}.\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error fetching {symbol}: {e}\")\n",
    "\n",
    "def main():\n",
    "    for ticker in TICKERS:\n",
    "        fetch_and_save_stock_data(ticker)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02d2bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "ingest_filepath = f\"/home/Stock_pipeline/data/raw/{timestamp}/\"\n",
    "\n",
    "processed_filepath = f\"/home/Stock_pipeline/data/processed/{timestamp}/\"\n",
    "os.makedirs(processed_filepath, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9c414bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: /home/Stock_pipeline/data/processed/2025-06-04/AAPL_processed_2025-06-04.csv\n",
      "Processed and saved: /home/Stock_pipeline/data/processed/2025-06-04/MSFT_processed_2025-06-04.csv\n",
      "Processed and saved: /home/Stock_pipeline/data/processed/2025-06-04/AMZN_processed_2025-06-04.csv\n",
      "Processed and saved: /home/Stock_pipeline/data/processed/2025-06-04/TSLA_processed_2025-06-04.csv\n",
      "Processed and saved: /home/Stock_pipeline/data/processed/2025-06-04/NVDA_processed_2025-06-04.csv\n",
      "Processed and saved: /home/Stock_pipeline/data/processed/2025-06-04/AAPL_processed_2025-06-04.csv\n",
      "Processed and saved: /home/Stock_pipeline/data/processed/2025-06-04/MSFT_processed_2025-06-04.csv\n",
      "Processed and saved: /home/Stock_pipeline/data/processed/2025-06-04/AMZN_processed_2025-06-04.csv\n",
      "Processed and saved: /home/Stock_pipeline/data/processed/2025-06-04/TSLA_processed_2025-06-04.csv\n",
      "Processed and saved: /home/Stock_pipeline/data/processed/2025-06-04/NVDA_processed_2025-06-04.csv\n"
     ]
    }
   ],
   "source": [
    "def process_stock_file(filepath):\n",
    "    df = pd.read_csv(filepath, parse_dates=[\"date\"])\n",
    "    \n",
    "    \n",
    "\n",
    "    # Keep relevant columns only\n",
    "    df.rename(columns={\"4. close\": \"close\", \"5. volume\": \"volume\"}, inplace=True)\n",
    "    df = df[[\"date\", \"close\", \"volume\", \"ticker\"]].copy()\n",
    "    # df = df[\"date\"] = pd.to_datetime(df_all[\"date\"]).dt.date\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    # Daily % change\n",
    "    df[\"percentage_change\"] = df[\"close\"].pct_change() * 100\n",
    "\n",
    "    # Moving Averages\n",
    "    df[\"movingAverage_7\"] = df[\"close\"].rolling(window=7).mean()\n",
    "    df[\"movingAverage_30\"] = df[\"close\"].rolling(window=30).mean()\n",
    "\n",
    "    # Volatility (rolling std deviation)\n",
    "    df[\"volatility\"] = df[\"close\"].rolling(window=30).std()\n",
    "    \n",
    "    df.dropna(inplace=True)  # Drop rows with NaN values after calculations\n",
    "    df.drop_duplicates()  # Drop duplicate rows if any\n",
    "\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    combined_df = []\n",
    "\n",
    "    for filename in os.listdir(ingest_filepath):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            filepath = os.path.join(ingest_filepath, filename)\n",
    "            df_processed = process_stock_file(filepath)\n",
    "\n",
    "            # Save back to processed CSV\n",
    "            out_file = os.path.join(processed_filepath, filename.replace(\"_daily\", \"_processed\"))\n",
    "            df_processed.to_csv(out_file, index=False)\n",
    "            print(f\"Processed and saved: {out_file}\")\n",
    "\n",
    "            combined_df.append(df_processed)\n",
    "\n",
    "    # Concatenate all processed files into one DataFrame\n",
    "    final_df = pd.concat(combined_df, ignore_index=True)\n",
    "    return final_df\n",
    "\n",
    "def processed_df():\n",
    "    return df_all\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    df_all = main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "53eb554a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-04 08:16:09,838 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2025-06-04 08:16:09,848 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-06-04 08:16:09,855 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2025-06-04 08:16:09,863 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-06-04 08:16:09,871 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2025-06-04 08:16:09,880 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-06-04 08:16:09,887 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-04 08:16:09,900 INFO sqlalchemy.engine.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where n.nspname=%(schema)s and relname=%(name)s\n",
      "2025-06-04 08:16:09,904 INFO sqlalchemy.engine.Engine [generated in 0.00422s] {'schema': 'public', 'name': 'stock_prices'}\n",
      "2025-06-04 08:16:09,914 INFO sqlalchemy.engine.Engine \n",
      "DROP TABLE public.stock_prices\n",
      "2025-06-04 08:16:09,918 INFO sqlalchemy.engine.Engine [no key 0.00355s] {}\n",
      "2025-06-04 08:16:09,929 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2025-06-04 08:16:09,945 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-04 08:16:09,953 INFO sqlalchemy.engine.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where n.nspname=%(schema)s and relname=%(name)s\n",
      "2025-06-04 08:16:09,958 INFO sqlalchemy.engine.Engine [cached since 0.0588s ago] {'schema': 'public', 'name': 'stock_prices'}\n",
      "2025-06-04 08:16:09,987 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE public.stock_prices (\n",
      "\tdate DATE NOT NULL, \n",
      "\tclose DOUBLE PRECISION, \n",
      "\tvolume BIGINT, \n",
      "\tticker VARCHAR NOT NULL, \n",
      "\tpercentage_change DOUBLE PRECISION, \n",
      "\t\"movingAverage_7\" DOUBLE PRECISION, \n",
      "\t\"movingAverage_30\" DOUBLE PRECISION, \n",
      "\tvolatility DOUBLE PRECISION, \n",
      "\tPRIMARY KEY (date, ticker)\n",
      ")\n",
      "\n",
      "\n",
      "2025-06-04 08:16:09,990 INFO sqlalchemy.engine.Engine [no key 0.00337s] {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-04 08:16:10,043 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2025-06-04 08:16:10,160 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-04 08:16:10,165 INFO sqlalchemy.engine.Engine DELETE FROM public.stock_prices\n",
      "2025-06-04 08:16:10,175 INFO sqlalchemy.engine.Engine [generated in 0.01068s] {}\n",
      "2025-06-04 08:16:10,971 INFO sqlalchemy.engine.Engine INSERT INTO public.stock_prices (date, close, volume, ticker, percentage_change, \"movingAverage_7\", \"movingAverage_30\", volatility) VALUES (%(date)s, %(close)s, %(volume)s, %(ticker)s, %(percentage_change)s, %(movingAverage_7)s, %(movingAverage_30)s, %(volatility)s)\n",
      "2025-06-04 08:16:10,973 INFO sqlalchemy.engine.Engine [generated in 0.34309s] ({'date': datetime.date(1999, 12, 13), 'close': 99.0, 'volume': 4731800.0, 'ticker': 'AAPL', 'percentage_change': -3.8834951456310662, 'movingAverage_7': 109.44571428571427, 'movingAverage_30': 95.65066666666667, 'volatility': 10.403151025740602}, {'date': datetime.date(1999, 12, 14), 'close': 94.87, 'volume': 3891700.0, 'ticker': 'AAPL', 'percentage_change': -4.171717171717171, 'movingAverage_7': 106.57000000000001, 'movingAverage_30': 96.22566666666667, 'volatility': 9.833312026082504}, {'date': datetime.date(1999, 12, 15), 'close': 97.0, 'volume': 5562300.0, 'ticker': 'AAPL', 'percentage_change': 2.2451776114683186, 'movingAverage_7': 103.85571428571428, 'movingAverage_30': 96.784, 'volatility': 9.359030895896474}, {'date': datetime.date(1999, 12, 16), 'close': 98.31, 'volume': 4141300.0, 'ticker': 'AAPL', 'percentage_change': 1.3505154639175343, 'movingAverage_7': 101.07000000000001, 'movingAverage_30': 97.34433333333332, 'volatility': 8.90459226092544}, {'date': datetime.date(1999, 12, 17), 'close': 100.0, 'volume': 4419700.0, 'ticker': 'AAPL', 'percentage_change': 1.7190519784355596, 'movingAverage_7': 99.63285714285715, 'movingAverage_30': 97.89033333333333, 'volatility': 8.52827527671347}, {'date': datetime.date(1999, 12, 20), 'close': 98.0, 'volume': 2535600.0, 'ticker': 'AAPL', 'percentage_change': -2.0000000000000018, 'movingAverage_7': 98.59714285714287, 'movingAverage_30': 98.21333333333332, 'volatility': 8.334209241323428}, {'date': datetime.date(1999, 12, 21), 'close': 102.5, 'volume': 2746400.0, 'ticker': 'AAPL', 'percentage_change': 4.591836734693877, 'movingAverage_7': 98.5257142857143, 'movingAverage_30': 98.41766666666666, 'volatility': 8.362554750434995}, {'date': datetime.date(1999, 12, 22), 'close': 99.94, 'volume': 2920300.0, 'ticker': 'AAPL', 'percentage_change': -2.4975609756097583, 'movingAverage_7': 98.66000000000001, 'movingAverage_30': 98.76166666666667, 'volatility': 8.198834687312887}  ... displaying 10 of 29355 total bound parameter sets ...  {'date': datetime.date(2025, 6, 2), 'close': 137.38, 'volume': 197663116.0, 'ticker': 'NVDA', 'percentage_change': 1.6650632724043435, 'movingAverage_7': 135.16142857142856, 'movingAverage_30': 121.785, 'volatility': 13.214603403176968}, {'date': datetime.date(2025, 6, 3), 'close': 141.22, 'volume': 225578783.0, 'ticker': 'NVDA', 'percentage_change': 2.795166690930273, 'movingAverage_7': 136.35999999999999, 'movingAverage_30': 123.262, 'volatility': 12.808475480623743})\n",
      "Data loaded successfully!\n",
      "2025-06-04 08:16:12,700 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, String, Float, Integer, Date\n",
    "from sqlalchemy.dialects.postgresql import DOUBLE_PRECISION, BIGINT\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from process import main\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Connect to PostgreSQL via SQLAlchemy\n",
    "load_dotenv()\n",
    "user = os.getenv(\"PGUSER\")\n",
    "password = os.getenv(\"PGPASSWORD\")\n",
    "host = os.getenv(\"PGHOST\", \"localhost\")\n",
    "port = os.getenv(\"PGPORT\", \"5432\")\n",
    "database = os.getenv(\"PGDATABASE\")\n",
    "\n",
    "pg_conn = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "engine = create_engine(pg_conn, echo=True)\n",
    "\n",
    "\n",
    "metadata = MetaData(schema=\"public\")\n",
    "\n",
    "# Define your table schema explicitly\n",
    "stock_prices = Table(\n",
    "    'stock_prices', metadata,\n",
    "    Column('date', Date, primary_key=True),\n",
    "    Column('close', DOUBLE_PRECISION),\n",
    "    Column('volume', BIGINT),\n",
    "    Column('ticker', String, primary_key=True),\n",
    "    Column('percentage_change', DOUBLE_PRECISION),\n",
    "    Column('movingAverage_7', DOUBLE_PRECISION),\n",
    "    Column('movingAverage_30', DOUBLE_PRECISION),\n",
    "    Column('volatility', DOUBLE_PRECISION),\n",
    ")\n",
    "\n",
    "# Create the table in DB (if not exists)\n",
    "stock_prices.drop(engine, checkfirst=True)  # Drops the table if it exists\n",
    "metadata.create_all(engine)  # Recreates it with new schema\n",
    "\n",
    "\n",
    "# Example function to load df into DB\n",
    "def load_data(df, table, conn):\n",
    "    try:\n",
    "        # Insert data row by row (you can optimize with bulk_insert_mappings or df.to_sql)\n",
    "        conn.execute(table.delete())  # Optional: clear existing data\n",
    "        conn.execute(table.insert(), df.to_dict(orient='records'))\n",
    "        print(\"Data loaded successfully!\")\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "\n",
    "# Load and process your CSV file (adjust as needed)\n",
    "def main3():\n",
    "    df_all = processed_df()\n",
    "    df_all[\"date\"] = pd.to_datetime(df_all[\"date\"]).dt.date\n",
    "\n",
    "\n",
    "    # Make sure df columns match your table columns exactly!\n",
    "    # # Example: reorder and rename columns if needed\n",
    "    # df = df[['date', 'close','volume','ticker', 'percentage_change', 'movingAverage_7', 'movingAverage_30', 'volatility']]\n",
    "    \n",
    "    with engine.begin() as conn:  # transaction scope\n",
    "        load_data(df_all, stock_prices, conn)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main3()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5ed1ed13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates found:\n",
      " date                 8\n",
      "close                8\n",
      "volume               8\n",
      "ticker               8\n",
      "percentage_change    8\n",
      "movingAverage_7      8\n",
      "movingAverage_30     8\n",
      "volatility           8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "duplicates = df_all[df_all.duplicated(subset=['date', 'close'], keep=False)].count()\n",
    "print(\"Duplicates found:\\n\", duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "768741b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date   close     volume ticker  percentage_change  movingAverage_7  \\\n",
      "0 1999-12-13   99.00  4731800.0   AAPL          -3.883495       109.445714   \n",
      "1 1999-12-14   94.87  3891700.0   AAPL          -4.171717       106.570000   \n",
      "2 1999-12-15   97.00  5562300.0   AAPL           2.245178       103.855714   \n",
      "3 1999-12-16   98.31  4141300.0   AAPL           1.350515       101.070000   \n",
      "4 1999-12-17  100.00  4419700.0   AAPL           1.719052        99.632857   \n",
      "\n",
      "   movingAverage_30  volatility  \n",
      "0         95.650667   10.403151  \n",
      "1         96.225667    9.833312  \n",
      "2         96.784000    9.359031  \n",
      "3         97.344333    8.904592  \n",
      "4         97.890333    8.528275  \n"
     ]
    }
   ],
   "source": [
    "from process import processed_df\n",
    "\n",
    "df = processed_df()\n",
    "print(df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
