{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c76b6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from alpha_vantage.timeseries import TimeSeries as TS\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f454afe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_ngx_list():\n",
    "    url = \"https://www.african-markets.com/en/stock-markets/ngse/listed-companies\"\n",
    "\n",
    "    # Session with retries\n",
    "    session = requests.Session()\n",
    "    retries = Retry(total=5, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\n",
    "    session.mount(\"http://\", HTTPAdapter(max_retries=retries))\n",
    "    session.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "\n",
    "    # Add headers to look like a browser\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                      \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # Fetch page\n",
    "    r = session.get(url, headers=headers, timeout=30)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    # Locate the table\n",
    "    table = soup.find(\"table\")\n",
    "    rows = table.find_all(\"tr\")\n",
    "\n",
    "    # Extract headers\n",
    "    header_cells = rows[0].find_all([\"th\", \"td\"])\n",
    "    headers = [cell.get_text(strip=True) for cell in header_cells]\n",
    "\n",
    "    # Extract rows\n",
    "    data = []\n",
    "    for row in rows[1:]:\n",
    "        cols = [td.get_text(strip=True) for td in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            data.append(cols)\n",
    "\n",
    "    # Fallback headers if missing\n",
    "    if not headers:\n",
    "        headers = [f\"Col_{i+1}\" for i in range(len(data[0]))]\n",
    "\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94954635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sector",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Price",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "1D",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "YTD",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "M.Cap",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "e9475746-944e-4160-ac91-53ed197ace0c",
       "rows": [
        [
         "0",
         "African Alliance Insurance",
         "Financials",
         "0.20",
         "-",
         "-",
         "4.11",
         "05/12"
        ],
        [
         "1",
         "McNichols",
         "Consumer Goods",
         "2.60",
         "-2.26%",
         "+61.49%",
         "2.9",
         "05/12"
        ],
        [
         "2",
         "Multi-Trex Integrated Foods",
         "Consumer Goods",
         "0.36",
         "-",
         "-",
         "2.24",
         "05/12"
        ],
        [
         "3",
         "Livingtrust Mortgage Bank",
         "Financials",
         "3.38",
         "+4.64%",
         "-22.83%",
         "16.89",
         "05/12"
        ],
        [
         "4",
         "Veritas Kapital Assurance",
         "Financials",
         "1.74",
         "+8.07%",
         "+27.94%",
         "24.12",
         "05/12"
        ],
        [
         "5",
         "Abbey Mortgage Bank",
         "Financials",
         "5.85",
         "-",
         "+95.00%",
         "59.4",
         "05/12"
        ],
        [
         "6",
         "ABC Transport",
         "Consumer Services",
         "3.10",
         "-9.88%",
         "+152.03%",
         "5.13",
         "05/12"
        ],
        [
         "7",
         "Academy Press",
         "Industrials",
         "7.35",
         "-",
         "+145.00%",
         "6.66",
         "05/12"
        ],
        [
         "8",
         "Africa Prudential",
         "Technology",
         "13.00",
         "+0.78%",
         "-36.74%",
         "52",
         "05/12"
        ],
        [
         "9",
         "Afromedia",
         "Consumer Services",
         "0.24",
         "-",
         "-",
         "1.06",
         "05/12"
        ],
        [
         "10",
         "Aiico Insurance",
         "Financials",
         "3.51",
         "-1.40%",
         "+145.45%",
         "128.48",
         "05/12"
        ],
        [
         "11",
         "Aluminium Extrusion Industries",
         "Basic Materials",
         "7.15",
         "-",
         "-",
         "1.57",
         "05/12"
        ],
        [
         "12",
         "Aso Savings And Loans",
         "Financials",
         "1.07",
         "-",
         "+114.00%",
         "15.77",
         "05/12"
        ],
        [
         "13",
         "Austin Laz & Company",
         "Industrials",
         "2.36",
         "-",
         "+29.67%",
         "2.54",
         "05/12"
        ],
        [
         "14",
         "Berger Paints",
         "Basic Materials",
         "35.80",
         "-",
         "+79.00%",
         "10.37",
         "05/12"
        ],
        [
         "15",
         "Beta Glass Co",
         "Industrials",
         "370.00",
         "-",
         "+470.11%",
         "184.98",
         "05/12"
        ],
        [
         "16",
         "Industrial and Medical Gases Nigeria",
         "Basic Materials",
         "32.40",
         "-",
         "-14.62%",
         "23.68",
         "05/12"
        ],
        [
         "17",
         "Cadbury Nigeria",
         "Consumer Goods",
         "57.90",
         "-",
         "+169.30%",
         "132.02",
         "05/12"
        ],
        [
         "18",
         "CAP",
         "Basic Materials",
         "68.50",
         "-",
         "+80.26%",
         "55.81",
         "05/12"
        ],
        [
         "19",
         "Caverton Offshore Support Group",
         "Oil & Gas",
         "4.90",
         "-",
         "+111.21%",
         "16.41",
         "05/12"
        ],
        [
         "20",
         "Champion Breweries",
         "Consumer Goods",
         "14.20",
         "-1.73%",
         "+272.70%",
         "127.06",
         "05/12"
        ],
        [
         "21",
         "Chams",
         "Technology",
         "3.06",
         "+3.73%",
         "+53.77%",
         "20.35",
         "05/12"
        ],
        [
         "22",
         "Chellarams",
         "Industrials",
         "14.65",
         "-",
         "+295.95%",
         "10.59",
         "05/12"
        ],
        [
         "23",
         "C & I Leasing",
         "Industrials",
         "5.28",
         "-",
         "+40.05%",
         "15.56",
         "05/12"
        ],
        [
         "24",
         "Conoil",
         "Oil & Gas",
         "187.20",
         "-",
         "-51.65%",
         "129.9",
         "05/12"
        ],
        [
         "25",
         "Cornerstone Insurance",
         "Financials",
         "5.50",
         "-1.08%",
         "+52.78%",
         "99.91",
         "05/12"
        ],
        [
         "26",
         "Custodian Investment",
         "Financials",
         "39.90",
         "-",
         "+133.33%",
         "234.68",
         "05/12"
        ],
        [
         "27",
         "Cutix",
         "Industrials",
         "3.00",
         "-0.33%",
         "+30.43%",
         "21.13",
         "05/12"
        ],
        [
         "28",
         "CWG",
         "Technology",
         "18.90",
         "+5.00%",
         "+145.45%",
         "47.71",
         "05/12"
        ],
        [
         "29",
         "Daar Communications",
         "Consumer Services",
         "0.98",
         "-",
         "+55.56%",
         "11.76",
         "05/12"
        ],
        [
         "30",
         "Dangote Cement",
         "Industrials",
         "614.90",
         "+4.57%",
         "+28.43%",
         "10375.55",
         "05/12"
        ],
        [
         "31",
         "Dangote Sugar Refinery",
         "Consumer Goods",
         "53.95",
         "+0.19%",
         "+66.00%",
         "655.32",
         "05/12"
        ],
        [
         "32",
         "Deap Capital Management & Trust",
         "Financials",
         "1.60",
         "+7.38%",
         "+35.59%",
         "2.4",
         "05/12"
        ],
        [
         "33",
         "Meyer",
         "Basic Materials",
         "13.10",
         "-",
         "+55.40%",
         "6.95",
         "05/12"
        ],
        [
         "34",
         "DN Tyre & Rubber",
         "Consumer Services",
         "0.20",
         "-",
         "-",
         "0.95",
         "05/12"
        ],
        [
         "35",
         "Ekocorp",
         "Health Care",
         "5.80",
         "-",
         "-",
         "2.89",
         "05/12"
        ],
        [
         "36",
         "Ellah Lakes",
         "Consumer Goods",
         "13.68",
         "+4.11%",
         "+332.91%",
         "52.77",
         "05/12"
        ],
        [
         "37",
         "Nigerian Enamelware",
         "Consumer Goods",
         "40.50",
         "-",
         "+109.84%",
         "3.07",
         "05/12"
        ],
        [
         "38",
         "SUNU Assurances Nigeria",
         "Financials",
         "4.34",
         "-0.23%",
         "-59.63%",
         "25.21",
         "05/12"
        ],
        [
         "39",
         "Eterna",
         "Oil & Gas",
         "35.50",
         "-",
         "+46.09%",
         "46.29",
         "05/12"
        ],
        [
         "40",
         "E-Tranzact International",
         "Technology",
         "14.00",
         "-",
         "+115.38%",
         "128.79",
         "05/12"
        ],
        [
         "41",
         "First HoldCo Plc (FBNH)",
         "Financials",
         "31.50",
         "-0.16%",
         "+12.30%",
         "1319.15",
         "05/12"
        ],
        [
         "42",
         "FCMB Group",
         "Financials",
         "10.90",
         "+3.81%",
         "+15.96%",
         "466.21",
         "05/12"
        ],
        [
         "43",
         "Fidelity Bank",
         "Financials",
         "19.20",
         "+1.05%",
         "+9.71%",
         "964.07",
         "05/12"
        ],
        [
         "44",
         "Fidson Healthcare",
         "Health Care",
         "40.00",
         "-",
         "+158.06%",
         "91.79",
         "05/12"
        ],
        [
         "45",
         "FTN Cocoa Processors",
         "Consumer Goods",
         "4.75",
         "-4.62%",
         "+160.99%",
         "18.52",
         "05/12"
        ],
        [
         "46",
         "Golden Guinea Breweries",
         "Consumer Goods",
         "7.10",
         "-",
         "-17.82%",
         "7.27",
         "05/12"
        ],
        [
         "47",
         "Guinea Insurance",
         "Financials",
         "1.15",
         "-3.36%",
         "+41.98%",
         "9.13",
         "05/12"
        ],
        [
         "48",
         "Guinness Nigeria",
         "Consumer Goods",
         "198.00",
         "-",
         "+181.85%",
         "433.69",
         "05/12"
        ],
        [
         "49",
         "Consolidated Hallmark Insurance",
         "Financials",
         "3.98",
         "+1.79%",
         "+15.36%",
         "43.14",
         "05/12"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 156
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Price</th>\n",
       "      <th>1D</th>\n",
       "      <th>YTD</th>\n",
       "      <th>M.Cap</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>African Alliance Insurance</td>\n",
       "      <td>Financials</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>4.11</td>\n",
       "      <td>05/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McNichols</td>\n",
       "      <td>Consumer Goods</td>\n",
       "      <td>2.60</td>\n",
       "      <td>-2.26%</td>\n",
       "      <td>+61.49%</td>\n",
       "      <td>2.9</td>\n",
       "      <td>05/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multi-Trex Integrated Foods</td>\n",
       "      <td>Consumer Goods</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2.24</td>\n",
       "      <td>05/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Livingtrust Mortgage Bank</td>\n",
       "      <td>Financials</td>\n",
       "      <td>3.38</td>\n",
       "      <td>+4.64%</td>\n",
       "      <td>-22.83%</td>\n",
       "      <td>16.89</td>\n",
       "      <td>05/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Veritas Kapital Assurance</td>\n",
       "      <td>Financials</td>\n",
       "      <td>1.74</td>\n",
       "      <td>+8.07%</td>\n",
       "      <td>+27.94%</td>\n",
       "      <td>24.12</td>\n",
       "      <td>05/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Transcorp Power</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>307.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-14.70%</td>\n",
       "      <td>2302.5</td>\n",
       "      <td>05/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Aradel Holdings</td>\n",
       "      <td>Oil &amp; Gas</td>\n",
       "      <td>680.00</td>\n",
       "      <td>-</td>\n",
       "      <td>+13.71%</td>\n",
       "      <td>2954.49</td>\n",
       "      <td>05/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>UPDC REIT</td>\n",
       "      <td>Financials</td>\n",
       "      <td>6.80</td>\n",
       "      <td>+1.49%</td>\n",
       "      <td>+36.00%</td>\n",
       "      <td>18.14</td>\n",
       "      <td>05/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Legend Internet</td>\n",
       "      <td>Telecom</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>10</td>\n",
       "      <td>05/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>MOFI Real Estate Investment Fund</td>\n",
       "      <td>Financials</td>\n",
       "      <td>100.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>05/12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Company          Sector   Price      1D  \\\n",
       "0          African Alliance Insurance      Financials    0.20       -   \n",
       "1                           McNichols  Consumer Goods    2.60  -2.26%   \n",
       "2         Multi-Trex Integrated Foods  Consumer Goods    0.36       -   \n",
       "3           Livingtrust Mortgage Bank      Financials    3.38  +4.64%   \n",
       "4           Veritas Kapital Assurance      Financials    1.74  +8.07%   \n",
       "..                                ...             ...     ...     ...   \n",
       "151                   Transcorp Power       Utilities  307.00       -   \n",
       "152                   Aradel Holdings       Oil & Gas  680.00       -   \n",
       "153                         UPDC REIT      Financials    6.80  +1.49%   \n",
       "154                   Legend Internet         Telecom    5.00       -   \n",
       "155  MOFI Real Estate Investment Fund      Financials  100.00       -   \n",
       "\n",
       "         YTD    M.Cap   Date  \n",
       "0          -     4.11  05/12  \n",
       "1    +61.49%      2.9  05/12  \n",
       "2          -     2.24  05/12  \n",
       "3    -22.83%    16.89  05/12  \n",
       "4    +27.94%    24.12  05/12  \n",
       "..       ...      ...    ...  \n",
       "151  -14.70%   2302.5  05/12  \n",
       "152  +13.71%  2954.49  05/12  \n",
       "153  +36.00%    18.14  05/12  \n",
       "154        -       10  05/12  \n",
       "155        -      100  05/12  \n",
       "\n",
       "[156 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nigeria = fetch_ngx_list()\n",
    "df_nigeria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb87b9da",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m movers\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     trending = \u001b[43mscrape_top_movers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m category, df \u001b[38;5;129;01min\u001b[39;00m trending.items():\n\u001b[32m     32\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mscrape_top_movers\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     13\u001b[39m categories = [\u001b[33m\"\u001b[39m\u001b[33mTop Gainers\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mTop Losers\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mTop Trades\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, category \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(categories):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     table = \u001b[43mtables\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     17\u001b[39m     rows = table.find(\u001b[33m\"\u001b[39m\u001b[33mtbody\u001b[39m\u001b[33m\"\u001b[39m).find_all(\u001b[33m\"\u001b[39m\u001b[33mtr\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m     data = []\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_top_movers():\n",
    "    url = \"https://ngxgroup.com/exchange/data/equities/\"\n",
    "    response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    tables = soup.find_all(\"table\")\n",
    "\n",
    "    movers = {}\n",
    "    categories = [\"Top Gainers\", \"Top Losers\", \"Top Trades\"]\n",
    "\n",
    "    for idx, category in enumerate(categories):\n",
    "        table = tables[idx]\n",
    "        rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "        data = []\n",
    "        for row in rows:\n",
    "            cols = [c.get_text(strip=True) for c in row.find_all(\"td\")]\n",
    "            if cols:\n",
    "                data.append(cols)\n",
    "        movers[category] = pd.DataFrame(\n",
    "            data, columns=[\"Symbol\", \"Price\", \"Change\", \"Volume\"]\n",
    "        )\n",
    "\n",
    "    return movers\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trending = scrape_top_movers()\n",
    "    for category, df in trending.items():\n",
    "        print(f\"\\n=== {category} ===\")\n",
    "        print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b423da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Company PreviousClosingPrice Opening Price   High    Low  Close  \\\n",
      "0          ABBEYBDS                  6.8           6.8     --     --   6.80   \n",
      "1          ABCTRANS                  4.3           4.3     --     --   4.30   \n",
      "2           ACADEMY                 9.54          9.54   9.60   9.60   9.60   \n",
      "3  ACCESSCORP [AWR]                   27         26.95  26.95  25.25  25.90   \n",
      "4   AFRINSURE [MRF]                  0.2           0.2     --     --   0.20   \n",
      "\n",
      "  Change Trades      Volume           Value Trade Date  \n",
      "0            29      95,266      671,152.50  19 Sep 25  \n",
      "1            47     151,140      654,553.06  19 Sep 25  \n",
      "2   0.06     46     489,373    4,720,865.92  19 Sep 25  \n",
      "3   -1.1   1404  29,413,174  765,239,030.25  19 Sep 25  \n",
      "4             0          --              --  19 Sep 25  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def get_equities_price_list():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    # set path to your driver if needed\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    url = \"https://ngxgroup.com/exchange/data/equities-price-list/\"\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # wait for JS to load the page; adjust if slower\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Now find the table(s) you want\n",
    "    table = soup.find(\"table\")  # you may need a more specific selector\n",
    "    rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "\n",
    "    data = []\n",
    "    headers = [th.get_text(strip=True) for th in table.find(\"thead\").find_all(\"th\")]\n",
    "    for row in rows:\n",
    "        cols = [td.get_text(strip=True) for td in row.find_all(\"td\")]\n",
    "        if len(cols) == len(headers):\n",
    "            data.append(cols)\n",
    "\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    driver.quit()\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = get_equities_price_list()\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8f981ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_ngx_historical(symbol, years=5):\n",
    "    \"\"\"\n",
    "    Fetch historical data for a specific NGX stock\n",
    "    Example URL pattern: https://www.african-markets.com/en/stock-markets/ngse/[symbol]/historical-data\n",
    "    \"\"\"\n",
    "    url = f\"https://www.african-markets.com/en/stock-markets/ngse/{symbol.lower()}/historical-data\"\n",
    "    \n",
    "    session = requests.Session()\n",
    "    retries = Retry(total=5, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\n",
    "    session.mount(\"http://\", HTTPAdapter(max_retries=retries))\n",
    "    session.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                      \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    r = session.get(url, headers=headers, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    \n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    table = soup.find(\"table\")  # Find historical price table\n",
    "    \n",
    "    # Parse table similar to your fetch_ngx_list function\n",
    "    rows = table.find_all(\"tr\")\n",
    "    data = []\n",
    "    for row in rows[1:]:\n",
    "        cols = [td.get_text(strip=True) for td in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            data.append(cols)\n",
    "    \n",
    "    headers = [th.get_text(strip=True) for th in rows[0].find_all([\"th\", \"td\"])]\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3460bf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error: 404 Client Error: Not Found for url: https://www.african-markets.com/en/stock-markets/ngse/dangcem/historical-data\n",
      "\n",
      "Trying alternative stocks...\n",
      "❌ MTNN failed: 404 Client Error: Not Found for url: https://www.african-markets.com/en/stock-markets/ngse/mtnn/historical-data\n",
      "❌ MTNN failed: 404 Client Error: Not Found for url: https://www.african-markets.com/en/stock-markets/ngse/mtnn/historical-data\n",
      "❌ ZENITHBANK failed: 404 Client Error: Not Found for url: https://www.african-markets.com/en/stock-markets/ngse/zenithbank/historical-data\n",
      "❌ ZENITHBANK failed: 404 Client Error: Not Found for url: https://www.african-markets.com/en/stock-markets/ngse/zenithbank/historical-data\n",
      "❌ GUARANTY failed: 404 Client Error: Not Found for url: https://www.african-markets.com/en/stock-markets/ngse/guaranty/historical-data\n",
      "❌ GUARANTY failed: 404 Client Error: Not Found for url: https://www.african-markets.com/en/stock-markets/ngse/guaranty/historical-data\n",
      "❌ NESTLE failed: 404 Client Error: Not Found for url: https://www.african-markets.com/en/stock-markets/ngse/nestle/historical-data\n",
      "❌ NESTLE failed: 404 Client Error: Not Found for url: https://www.african-markets.com/en/stock-markets/ngse/nestle/historical-data\n"
     ]
    }
   ],
   "source": [
    "# Test the historical data function with a major NGX stock\n",
    "# Let's try Dangote Cement (DANGCEM) - one of the largest companies\n",
    "\n",
    "try:\n",
    "    df_historical = fetch_ngx_historical(\"DANGCEM\")\n",
    "    print(f\"✅ Successfully fetched historical data for DANGCEM\")\n",
    "    print(f\"Shape: {df_historical.shape}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df_historical.head())\n",
    "    print(\"\\nColumns:\", df_historical.columns.tolist())\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    print(\"\\nTrying alternative stocks...\")\n",
    "    \n",
    "    # Try other major stocks\n",
    "    test_symbols = [\"MTNN\", \"ZENITHBANK\", \"GUARANTY\", \"NESTLE\"]\n",
    "    for symbol in test_symbols:\n",
    "        try:\n",
    "            df_test = fetch_ngx_historical(symbol)\n",
    "            print(f\"✅ {symbol} worked! Shape: {df_test.shape}\")\n",
    "            print(df_test.head())\n",
    "            break\n",
    "        except Exception as e2:\n",
    "            print(f\"❌ {symbol} failed: {e2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b18a782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 NGX companies from african-markets.com:\n",
      "                       Company  Price\n",
      "0   African Alliance Insurance   0.20\n",
      "1                    McNichols   2.60\n",
      "2  Multi-Trex Integrated Foods   0.36\n",
      "3    Livingtrust Mortgage Bank   3.38\n",
      "4    Veritas Kapital Assurance   1.74\n",
      "5          Abbey Mortgage Bank   5.85\n",
      "6                ABC Transport   3.10\n",
      "7                Academy Press   7.35\n",
      "8            Africa Prudential  13.00\n",
      "9                    Afromedia   0.24\n",
      "\n",
      "==================================================\n",
      "\n",
      "Testing with: African Alliance Insurance\n",
      "URL slug: african-alliance-insurance\n",
      "Full URL: https://www.african-markets.com/en/stock-markets/ngse/african-alliance-insurance/historical-data\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect the company names from the list to find the correct URL slug\n",
    "# Check the first few rows to see the actual company name format\n",
    "\n",
    "print(\"Top 10 NGX companies from african-markets.com:\")\n",
    "print(df_nigeria[['Company', 'Price']].head(10))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Try to construct URL from actual company name\n",
    "# African-markets likely uses slugified company names, not ticker symbols\n",
    "test_company = df_nigeria.iloc[0]['Company']\n",
    "test_slug = test_company.lower().replace(' ', '-').replace('.', '')\n",
    "\n",
    "print(f\"Testing with: {test_company}\")\n",
    "print(f\"URL slug: {test_slug}\")\n",
    "print(f\"Full URL: https://www.african-markets.com/en/stock-markets/ngse/{test_slug}/historical-data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a83a8ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://www.african-markets.com/en/stock-markets/ngse/african-alliance-insurance/historical-data\n",
      "❌ African Alliance Insurance: 404 Client Error: Not Found for url: https://www.african-markets.com/en/stock-markets/ngse/african-alliance-insurance/historical-data\n",
      "\n",
      "Fetching: https://www.african-markets.com/en/stock-markets/ngse/abbey-mortgage-bank/historical-data\n",
      "❌ African Alliance Insurance: 404 Client Error: Not Found for url: https://www.african-markets.com/en/stock-markets/ngse/african-alliance-insurance/historical-data\n",
      "\n",
      "Fetching: https://www.african-markets.com/en/stock-markets/ngse/abbey-mortgage-bank/historical-data\n",
      "❌ Abbey Mortgage Bank: 404 Client Error: Not Found for url: https://www.african-markets.com/en/stock-markets/ngse/abbey-mortgage-bank/historical-data\n",
      "\n",
      "Fetching: https://www.african-markets.com/en/stock-markets/ngse/africa-prudential/historical-data\n",
      "❌ Abbey Mortgage Bank: 404 Client Error: Not Found for url: https://www.african-markets.com/en/stock-markets/ngse/abbey-mortgage-bank/historical-data\n",
      "\n",
      "Fetching: https://www.african-markets.com/en/stock-markets/ngse/africa-prudential/historical-data\n",
      "❌ Africa Prudential: 404 Client Error: Not Found for url: https://www.african-markets.com/en/stock-markets/ngse/africa-prudential/historical-data\n",
      "\n",
      "❌ Africa Prudential: 404 Client Error: Not Found for url: https://www.african-markets.com/en/stock-markets/ngse/africa-prudential/historical-data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fetch_ngx_historical_by_name(company_name, years=5):\n",
    "    \"\"\"\n",
    "    Fetch historical data for a specific NGX stock using company name\n",
    "    \"\"\"\n",
    "    # Create URL slug from company name\n",
    "    slug = company_name.lower().replace(' ', '-').replace('.', '').replace(',', '')\n",
    "    url = f\"https://www.african-markets.com/en/stock-markets/ngse/{slug}/historical-data\"\n",
    "    \n",
    "    print(f\"Fetching: {url}\")\n",
    "    \n",
    "    session = requests.Session()\n",
    "    retries = Retry(total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\n",
    "    session.mount(\"http://\", HTTPAdapter(max_retries=retries))\n",
    "    session.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                      \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    r = session.get(url, headers=headers, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    \n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    table = soup.find(\"table\")\n",
    "    \n",
    "    if not table:\n",
    "        raise ValueError(f\"No table found on page for {company_name}\")\n",
    "    \n",
    "    rows = table.find_all(\"tr\")\n",
    "    \n",
    "    # Extract headers\n",
    "    header_cells = rows[0].find_all([\"th\", \"td\"])\n",
    "    headers = [cell.get_text(strip=True) for cell in header_cells]\n",
    "    \n",
    "    # Extract data rows\n",
    "    data = []\n",
    "    for row in rows[1:]:\n",
    "        cols = [td.get_text(strip=True) for td in row.find_all(\"td\")]\n",
    "        if cols:\n",
    "            data.append(cols)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    df['Company'] = company_name\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Test with a few companies from the list\n",
    "test_companies = [\n",
    "    \"African Alliance Insurance\",\n",
    "    \"Abbey Mortgage Bank\", \n",
    "    \"Africa Prudential\"\n",
    "]\n",
    "\n",
    "for company in test_companies:\n",
    "    try:\n",
    "        df_hist = fetch_ngx_historical_by_name(company)\n",
    "        print(f\"✅ {company}: {df_hist.shape[0]} rows\")\n",
    "        print(df_hist.head(3))\n",
    "        print()\n",
    "        break  # If one works, stop testing\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {company}: {e}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47841e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First company: African Alliance Insurance\n",
      "Link structure: listed-companies/company?code=AFRINSURE\n",
      "Full URL: https://www.african-markets.comlisted-companies/company?code=AFRINSURE\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='www.african-markets.comlisted-companies', port=443): Max retries exceeded with url: /company?code=AFRINSURE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f1b71e64a70>: Failed to resolve 'www.african-markets.comlisted-companies' ([Errno -2] Name or service not known)\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mgaierror\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/data_engineering/lib/python3.12/site-packages/urllib3/connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/data_engineering/lib/python3.12/site-packages/urllib3/util/connection.py:60\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, label empty or too long\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     61\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/socket.py:963\u001b[39m, in \u001b[36mgetaddrinfo\u001b[39m\u001b[34m(host, port, family, type, proto, flags)\u001b[39m\n\u001b[32m    962\u001b[39m addrlist = []\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    964\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[31mgaierror\u001b[39m: [Errno -2] Name or service not known",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNameResolutionError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/data_engineering/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/data_engineering/lib/python3.12/site-packages/urllib3/connectionpool.py:488\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    487\u001b[39m         new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/data_engineering/lib/python3.12/site-packages/urllib3/connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/data_engineering/lib/python3.12/site-packages/urllib3/connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/data_engineering/lib/python3.12/site-packages/urllib3/connection.py:753\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    752\u001b[39m sock: socket.socket | ssl.SSLSocket\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m server_hostname: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28mself\u001b[39m.host\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/data_engineering/lib/python3.12/site-packages/urllib3/connection.py:205\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mNameResolutionError\u001b[39m: <urllib3.connection.HTTPSConnection object at 0x7f1b71e64a70>: Failed to resolve 'www.african-markets.comlisted-companies' ([Errno -2] Name or service not known)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/data_engineering/lib/python3.12/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/data_engineering/lib/python3.12/site-packages/urllib3/connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/data_engineering/lib/python3.12/site-packages/urllib3/util/retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPSConnectionPool(host='www.african-markets.comlisted-companies', port=443): Max retries exceeded with url: /company?code=AFRINSURE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f1b71e64a70>: Failed to resolve 'www.african-markets.comlisted-companies' ([Errno -2] Name or service not known)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Try to access this actual page and see if historical data link exists\u001b[39;00m\n\u001b[32m     29\u001b[39m full_url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://www.african-markets.com\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhref\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m r2 = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m soup2 = BeautifulSoup(r2.text, \u001b[33m\"\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Look for historical data link on the company page\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/data_engineering/lib/python3.12/site-packages/requests/sessions.py:602\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    595\u001b[39m \n\u001b[32m    596\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[33;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    601\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/data_engineering/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/data_engineering/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/data_engineering/lib/python3.12/site-packages/requests/adapters.py:677\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    673\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, _SSLError):\n\u001b[32m    674\u001b[39m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[32m    675\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n",
      "\u001b[31mConnectionError\u001b[39m: HTTPSConnectionPool(host='www.african-markets.comlisted-companies', port=443): Max retries exceeded with url: /company?code=AFRINSURE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f1b71e64a70>: Failed to resolve 'www.african-markets.comlisted-companies' ([Errno -2] Name or service not known)\"))"
     ]
    }
   ],
   "source": [
    "# Let's inspect the actual links on the NGX company listing page\n",
    "# to see what the real URL structure is\n",
    "\n",
    "url = \"https://www.african-markets.com/en/stock-markets/ngse/listed-companies\"\n",
    "session = requests.Session()\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "r = session.get(url, headers=headers, timeout=30)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "# Find the first company link in the table\n",
    "table = soup.find(\"table\")\n",
    "first_row = table.find(\"tbody\").find_all(\"tr\")[0]\n",
    "company_cell = first_row.find(\"td\")\n",
    "link = company_cell.find(\"a\")\n",
    "\n",
    "if link:\n",
    "    href = link.get('href')\n",
    "    company_name = link.get_text(strip=True)\n",
    "    print(f\"First company: {company_name}\")\n",
    "    print(f\"Link structure: {href}\")\n",
    "    print(f\"Full URL: https://www.african-markets.com{href}\")\n",
    "    \n",
    "    # Try to access this actual page and see if historical data link exists\n",
    "    full_url = f\"https://www.african-markets.com{href}\"\n",
    "    r2 = session.get(full_url, headers=headers, timeout=30)\n",
    "    soup2 = BeautifulSoup(r2.text, \"html.parser\")\n",
    "    \n",
    "    # Look for historical data link on the company page\n",
    "    hist_link = soup2.find(\"a\", string=lambda text: text and \"historical\" in text.lower())\n",
    "    if hist_link:\n",
    "        print(f\"\\n✅ Historical data link found: {hist_link.get('href')}\")\n",
    "    else:\n",
    "        print(\"\\n❌ No historical data link found on company page\")\n",
    "        print(\"Available links:\")\n",
    "        for a in soup2.find_all(\"a\", href=True)[:10]:\n",
    "            print(f\"  - {a.get_text(strip=True)}: {a.get('href')}\")\n",
    "else:\n",
    "    print(\"No link found in company cell\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f237e541",
   "metadata": {},
   "source": [
    "## 🎯 Key Finding: African Markets Uses Stock CODES\n",
    "\n",
    "The URL structure is: `https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company?code=AFRINSURE`\n",
    "\n",
    "**Problem:** We need the stock CODE (e.g., `AFRINSURE`), not the company name.  \n",
    "**Solution:** Extract codes from the company list table or scrape them from the links.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cba93d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fetched 156 companies with stock codes\n",
      "\n",
      "First 10 companies:\n",
      "                       Company   Stock_Code  Price             Sector\n",
      "0   African Alliance Insurance    AFRINSURE   0.20         Financials\n",
      "1                    McNichols    MCNICHOLS   2.60     Consumer Goods\n",
      "2  Multi-Trex Integrated Foods    MULTITREX   0.36     Consumer Goods\n",
      "3    Livingtrust Mortgage Bank  LIVINGTRUST   3.38         Financials\n",
      "4    Veritas Kapital Assurance   VERITASKAP   1.74         Financials\n",
      "5          Abbey Mortgage Bank     ABBEYBDS   5.85         Financials\n",
      "6                ABC Transport     ABCTRANS   3.10  Consumer Services\n",
      "7                Academy Press      ACADEMY   7.35        Industrials\n",
      "8            Africa Prudential     AFRIPRUD  13.00         Technology\n",
      "9                    Afromedia    AFROMEDIA   0.24  Consumer Services\n"
     ]
    }
   ],
   "source": [
    "# Extract stock codes from the company list table\n",
    "def fetch_ngx_with_codes():\n",
    "    \"\"\"Fetch NGX company list including stock codes from href links\"\"\"\n",
    "    url = \"https://www.african-markets.com/en/stock-markets/ngse/listed-companies\"\n",
    "    \n",
    "    session = requests.Session()\n",
    "    retries = Retry(total=5, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\n",
    "    session.mount(\"http://\", HTTPAdapter(max_retries=retries))\n",
    "    session.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                      \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    r = session.get(url, headers=headers, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    \n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    table = soup.find(\"table\")\n",
    "    rows = table.find_all(\"tr\")\n",
    "    \n",
    "    # Extract headers\n",
    "    header_cells = rows[0].find_all([\"th\", \"td\"])\n",
    "    headers = [cell.get_text(strip=True) for cell in header_cells]\n",
    "    headers.append(\"Stock_Code\")  # Add new column for stock code\n",
    "    \n",
    "    # Extract rows and stock codes\n",
    "    data = []\n",
    "    for row in rows[1:]:\n",
    "        cols = [td.get_text(strip=True) for td in row.find_all(\"td\")]\n",
    "        \n",
    "        # Extract stock code from link\n",
    "        link = row.find(\"a\")\n",
    "        stock_code = None\n",
    "        if link and 'href' in link.attrs:\n",
    "            href = link['href']\n",
    "            # Extract code from URL like \"company?code=AFRINSURE\"\n",
    "            if '?code=' in href:\n",
    "                stock_code = href.split('?code=')[1]\n",
    "        \n",
    "        if cols:\n",
    "            cols.append(stock_code)\n",
    "            data.append(cols)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    return df\n",
    "\n",
    "# Fetch updated data with stock codes\n",
    "df_ngx_with_codes = fetch_ngx_with_codes()\n",
    "print(f\"✅ Fetched {len(df_ngx_with_codes)} companies with stock codes\")\n",
    "print(\"\\nFirst 10 companies:\")\n",
    "print(df_ngx_with_codes[['Company', 'Stock_Code', 'Price', 'Sector']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7241ec42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with: ['AFRINSURE', 'MCNICHOLS', 'MULTITREX', 'LIVINGTRUST', 'VERITASKAP']\n",
      "\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company/historical-data?code=AFRINSURE\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company?code=AFRINSURE&view=historical\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company?code=AFRINSURE&view=historical\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/afrinsure/historical-data\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/afrinsure/historical-data\n",
      "  Status: 404\n",
      "❌ AFRINSURE failed\n",
      "\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company/historical-data?code=MCNICHOLS\n",
      "  Status: 404\n",
      "❌ AFRINSURE failed\n",
      "\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company/historical-data?code=MCNICHOLS\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company?code=MCNICHOLS&view=historical\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company?code=MCNICHOLS&view=historical\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/mcnichols/historical-data\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/mcnichols/historical-data\n",
      "  Status: 404\n",
      "❌ MCNICHOLS failed\n",
      "\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company/historical-data?code=MULTITREX\n",
      "  Status: 404\n",
      "❌ MCNICHOLS failed\n",
      "\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company/historical-data?code=MULTITREX\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company?code=MULTITREX&view=historical\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company?code=MULTITREX&view=historical\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/multitrex/historical-data\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/multitrex/historical-data\n",
      "  Status: 404\n",
      "❌ MULTITREX failed\n",
      "\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company/historical-data?code=LIVINGTRUST\n",
      "  Status: 404\n",
      "❌ MULTITREX failed\n",
      "\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company/historical-data?code=LIVINGTRUST\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company?code=LIVINGTRUST&view=historical\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company?code=LIVINGTRUST&view=historical\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/livingtrust/historical-data\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/livingtrust/historical-data\n",
      "  Status: 404\n",
      "❌ LIVINGTRUST failed\n",
      "\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company/historical-data?code=VERITASKAP\n",
      "  Status: 404\n",
      "❌ LIVINGTRUST failed\n",
      "\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company/historical-data?code=VERITASKAP\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company?code=VERITASKAP&view=historical\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company?code=VERITASKAP&view=historical\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/veritaskap/historical-data\n",
      "  Status: 404\n",
      "Trying: https://www.african-markets.com/en/stock-markets/ngse/veritaskap/historical-data\n",
      "  Status: 404\n",
      "❌ VERITASKAP failed\n",
      "\n",
      "  Status: 404\n",
      "❌ VERITASKAP failed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now try fetching historical data with the correct stock code\n",
    "def fetch_ngx_historical_by_code(stock_code):\n",
    "    \"\"\"Fetch historical data using stock code\"\"\"\n",
    "    # Try different URL patterns\n",
    "    possible_urls = [\n",
    "        f\"https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company/historical-data?code={stock_code}\",\n",
    "        f\"https://www.african-markets.com/en/stock-markets/ngse/listed-companies/company?code={stock_code}&view=historical\",\n",
    "        f\"https://www.african-markets.com/en/stock-markets/ngse/{stock_code.lower()}/historical-data\",\n",
    "    ]\n",
    "    \n",
    "    session = requests.Session()\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                      \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    for url in possible_urls:\n",
    "        try:\n",
    "            print(f\"Trying: {url}\")\n",
    "            r = session.get(url, headers=headers, timeout=30)\n",
    "            \n",
    "            if r.status_code == 200:\n",
    "                soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "                table = soup.find(\"table\")\n",
    "                \n",
    "                if table:\n",
    "                    print(f\"✅ Found table at: {url}\")\n",
    "                    rows = table.find_all(\"tr\")\n",
    "                    \n",
    "                    # Extract headers\n",
    "                    header_cells = rows[0].find_all([\"th\", \"td\"])\n",
    "                    headers = [cell.get_text(strip=True) for cell in header_cells]\n",
    "                    \n",
    "                    # Extract data\n",
    "                    data = []\n",
    "                    for row in rows[1:]:\n",
    "                        cols = [td.get_text(strip=True) for td in row.find_all(\"td\")]\n",
    "                        if cols:\n",
    "                            data.append(cols)\n",
    "                    \n",
    "                    df = pd.DataFrame(data, columns=headers)\n",
    "                    df['Stock_Code'] = stock_code\n",
    "                    return df\n",
    "                else:\n",
    "                    print(f\"  No table found\")\n",
    "            else:\n",
    "                print(f\"  Status: {r.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "    \n",
    "    raise ValueError(f\"Could not fetch historical data for {stock_code} from any URL pattern\")\n",
    "\n",
    "# Test with first few stock codes\n",
    "test_codes = df_ngx_with_codes['Stock_Code'].head(5).tolist()\n",
    "print(f\"\\nTesting with: {test_codes}\\n\")\n",
    "\n",
    "for code in test_codes:\n",
    "    if code:  # Skip None values\n",
    "        try:\n",
    "            df_hist = fetch_ngx_historical_by_code(code)\n",
    "            print(f\"✅ SUCCESS for {code}!\")\n",
    "            print(df_hist.head(3))\n",
    "            print()\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {code} failed\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c270ae99",
   "metadata": {},
   "source": [
    "## 📊 **Verdict: Historical Data Not Available on African-Markets.com**\n",
    "\n",
    "After testing multiple URL patterns, **african-markets.com does NOT provide free historical data**.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ **Your Options for NGX Historical Data:**\n",
    "\n",
    "### **Option 1: Daily Collection (FREE & RECOMMENDED)** \n",
    "Start scraping daily and build your own history:\n",
    "```python\n",
    "# Save daily snapshot\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "df_ngx.to_csv(f\"data/raw/ngx/{timestamp}_snapshot.csv\")\n",
    "```\n",
    "- ✅ After 30 days → calculate moving averages\n",
    "- ✅ After 90 days → volatility analysis\n",
    "- ✅ Full control over data quality\n",
    "\n",
    "### **Option 2: Yahoo Finance (PARTIAL)**\n",
    "Try major NGX stocks with `.LG` suffix:\n",
    "```python\n",
    "import yfinance as yf\n",
    "yf.Ticker(\"DANGCEM.LG\").history(period=\"1y\")\n",
    "```\n",
    "- ⚠️ Only works for ~10-20 major stocks\n",
    "- ✅ Free and reliable\n",
    "\n",
    "### **Option 3: Investing.com (COMPLEX)**\n",
    "Web scrape with POST requests to their AJAX endpoint\n",
    "- ⚠️ Requires reverse-engineering their API\n",
    "- ⚠️ May get blocked/rate-limited\n",
    "\n",
    "### **Option 4: Paid Data Providers**\n",
    "- **NGX Data Portal** (official, expensive)\n",
    "- **Bloomberg Terminal** \n",
    "- **Refinitiv/Eikon**\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 **My Recommendation:**\n",
    "\n",
    "**Combine Option 1 + Option 2:**\n",
    "1. Use Yahoo Finance for major stocks (Dangote, MTN, Zenith, GTB)\n",
    "2. For all other stocks, start daily collection TODAY\n",
    "3. After 30 days, you'll have enough historical data for analysis\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
